# Cluster Visualization Guide

## Overview

The visualization system provides comprehensive insights into alert cluster groupings, rankings, and patterns.

## Output Files

### 1. `cluster_visualization.png`
**Multi-panel visualization dashboard showing:**
- Top 15 clusters by ranking score
- Cluster size distribution
- Severity distribution by cluster
- Top services by alert count
- Clustering method distribution
- Alert category distribution
- Cluster score vs alert count scatter plot

### 2. `cluster_detailed_summary.csv`
**Detailed tabular summary with:**
- Rank, ID, and name for each cluster
- Ranking score
- Total alerts and unique alert types
- Primary alert and service
- Severity breakdown (Critical, High, Warning, Info)
- Unique services count

### 3. `ranked_clusters.csv`
**Generated by consolidation pipeline with:**
- Cluster metadata
- Scores and rankings
- Alert counts and service information

## Running Visualizations

### Automatic
Visualizations are automatically generated after running the consolidation:
```bash
python alert_consolidation_complete.py
```

###  Manual
Run the visualization script separately:
```bash
python visualize_clusters.py
```

## Understanding the Rankings

### Ranking Score Components

The ranking score (0-100+) combines 5 factors:

1. **Repetition Score (40% weight)**
   - Measures how repetitive alerts are within a cluster
   - Lower unique/total ratio = higher score
   - Example: 100 alerts, 2 unique types = very high repetition

2. **Severity Impact (25% weight)**
   - Averages severity levels
   - Critical=5, High=4, Warning=2, Info=1
   - Higher severity = higher score

3. **Cluster Size (20% weight)**
   - More alerts = higher score
   - Capped at 100 for clusters with 20+ alerts

4. **Service Importance (15% weight)**
   - Based on graph PageRank centrality
   - Central services get higher scores

5. **Time Concentration (10% weight)**
   - Shorter time spans = higher score
   - Indicates alert storms

### Interpreting Scores

- **90-100+**: Critical repetitive alert storms
- **70-89**: High priority clusters requiring attention
- **50-69**: Moderate priority recurring patterns
- **30-49**: Low-moderate priority clusters
- **Below 30**: Sporadic or diverse alert patterns

## Cluster Name Format

Cluster names follow the pattern:
```
{alert_type}_{service}_{category}_{severity}
```

**Example:** `cpuhigh_paymentapi_saturation_critical`

Breaking it down:
- **cpuhigh**: Alert type keywords
- **paymentapi**: Primary service
- **saturation**: Alert category
- **critical**: Severity level

## Visualization Panels Explained

### Panel 1: Top Clusters by Score
Horizontal bar chart showing the most important/repetitive clusters
- Ordered by ranking score (highest on top)
- Color-coded by score intensity
- Shows alert counts

### Panel 2: Cluster Size Distribution
Histogram showing how alerts are distributed across clusters
- Helps identify if you have many small or few large clusters
- Shows median and mean sizes

### Panel 3: Severity Distribution
Stacked bar chart showing severity breakdown per cluster
- Critical (red), High (orange), Warning (yellow), Info (green)
- Identifies which clusters have high-severity issues

### Panel 4: Top Services by Alert Count
Shows which services generate the most alerts
- Focus on top 15 services
- Helps identify problematic services

### Panel 5: Clustering Method Distribution
Pie chart showing which clustering algorithm worked best
- Most clusters will use the same method
- Validates clustering quality

### Panel 6: Alert Category Distribution
Bar chart showing alert categories across all clusters
- Saturation, Anomaly, Error, Critical, etc.
- Helps understand alert patterns

### Panel 7: Cluster Score vs Alert Count
Scatter plot showing relationship between score and size
- Points colored by score
- Top 5 clusters labeled
- Shows if high scores correlate with alert count

## Using the Results

### For Incident Response
1. **Focus on Rank 1-5 clusters** - These are most repetitive/important
2. **Check severity distribution** - Prioritize critical/high clusters
3. **Identify service patterns** - Which services appear in top clusters?

### For Alert Tuning
1. **High score + High repetition** = Candidate for alert rules
2. **Cluster size trends** = Understand alert volume patterns
3. **Service patterns** = Identify noisy services

### For Capacity Planning
1. **Large clusters** = Potential capacity issues
2. **Time concentration** = Alert storm identification
3. **Service distribution** = Resource allocation insights

## Key Metrics

### Interpreting Cluster Metadata

**Alert Count**: Total alerts in cluster
- Higher = more frequent pattern

**Unique Alert Types**: Diversity of alerts
- Lower = more repetitive (better for deduplication)

**Unique Services**: Service span
- 1-2 = service-specific issue
- Many = infrastructure-wide issue

**Ranking Score**: Overall importance
- Higher = more critical/repetitive

## Quick Reference

### Top Priority Investigation
```python
# Get top 5 clusters
df_ranked = pd.read_csv('ranked_clusters.csv')
top_5 = df_ranked.head(5)

# For each cluster, investigate:
# 1. Check primary service
# 2. Review severity breakdown
# 3. Examine time patterns
# 4. Identify root cause
```

### Identifying Alert Storms
Look for clusters with:
- High ranking scores (>70)
- Large alert counts (20+)
- Short time spans
- Single alert type

### Finding Noisy Services
Check Panel 4 (Top Services) to identify:
- Services appearing in multiple top clusters
- Services with highest alert counts
- Candidates for alert tuning

## Troubleshooting

### No visualization generated?
1. Ensure `ranked_clusters.csv` exists
2. Check that matplotlib/seaborn are installed
3. Run `python visualize_clusters.py` manually

### Missing cluster information?
- Verify consolidation pipeline completed successfully
- Check for errors in the output logs
- Review `cluster_summary.csv` as fallback

### Scores seem incorrect?
- Verify data quality (no missing values)
- Check if outliers were removed properly
- Review score calculation factors

## Next Steps

1. **Review top clusters** in `cluster_detailed_summary.csv`
2. **Investigate root causes** for high-ranking clusters
3. **Tune alert rules** based on repetitive patterns
4. **Set up monitoring** for top-tier clusters
5. **Update runbooks** with cluster-specific responses


